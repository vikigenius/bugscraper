#+TITLE:
#+DATE:    November 8, 2019
#+SINCE:   {replace with next tagged release version}
#+STARTUP: inlineimages

* Table of Contents :TOC_3:noexport:
- [[#description][Description]]
- [[#prerequisites][Prerequisites]]
- [[#installation][Installation]]
- [[#usage][Usage]]
- [[#troubleshooting][Troubleshooting]]

* Description
A simple scraper to scrape bugs and comments from bugzilla using the REST API

* Prerequisites
Running the scraper only has three prerequisites:
- click
- tqdm
- requests

* Installation
Clone this repository, create a new environment and use the command
#+BEGIN_SRC org
pip install -e .
#+END_SRC
* Usage
Use the following command to scrape bugs
#+BEGIN_SRC org
buscraper bugscrape <subdomain> -s <save_dir> -i <start_id> -f <end_id>
#+END_SRC
The above command scrapes all bugs from subdomain starting from id start_id till
id end_id and stores them in "save_dir/bugs/" directory. The bugs are stored in files year.jsonl

Once all the bugs have been scraped, you can scrape all the comments
corresponding to the scraped bugs by using the command:
#+BEGIN_SRC org
buscraper commentscrape <subdomain> -s <save_dir>
#+END_SRC
The above command scrapes all comments and stores them in "save_dir/bugs/"
directory. The bugs are stored in files year_comments.jsonl. A metadata file is
also created ("bug_metadata.jsonl") that has information about all bug_ids
scraped, their year and the associated comment_ids.
* Troubleshooting
It is possible that the request sent is too large and might lead to issues.
Try reducing the chunk size using option -c while scraping bugs.
